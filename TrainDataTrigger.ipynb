{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb2621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from seqeval.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, AutoModelForTokenClassification\n",
    "\n",
    "from crf_layer import CRFLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab1a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset):\n",
    "    \"\"\"data_process\"\"\"\n",
    "\n",
    "    def label_data(data, start, l, _type):\n",
    "        \"\"\"label_data\"\"\"\n",
    "        for i in range(start, start + l):\n",
    "            suffix = \"B-\" if i == start else \"I-\"\n",
    "            data[i] = \"{}{}\".format(suffix, _type)\n",
    "        return data\n",
    "\n",
    "    output = []\n",
    "    for d_json in dataset:\n",
    "        _id = d_json[\"id\"]\n",
    "        text_a = [\n",
    "            \"，\" if t == \" \" or t == \"\\n\" or t == \"\\t\" else t\n",
    "            for t in list(d_json[\"text\"].lower())\n",
    "        ]\n",
    "        labels = [\"O\"] * len(text_a)\n",
    "        if len(d_json.get(\"event_list\", [])) == 0:\n",
    "            continue\n",
    "        for event in d_json.get(\"event_list\", []):\n",
    "            event_type = event[\"event_type\"]\n",
    "            start = event[\"trigger_start_index\"]\n",
    "            trigger = event[\"trigger\"]\n",
    "            if start >= 0:\n",
    "                labels = label_data(labels, start, len(trigger), event_type)\n",
    "        output.append({\n",
    "            \"tokens\": text_a, \"labels\": labels\n",
    "        })\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c733f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(dict_path):\n",
    "    \"\"\"load_dict\"\"\"\n",
    "    vocab = {}\n",
    "    for line in open(dict_path, 'r', encoding='utf-8'):\n",
    "        value, key = line.strip('\\n').split('\\t')\n",
    "        vocab[key] = int(value)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f81002",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vocab = load_dict(dict_path='./dictionary/trigger_tag.dict')\n",
    "id2label = {val: key for key, val in label_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec7071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050669e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_labels = len(label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3679747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext-large were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ef5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = tokenizer.vocab[tokenizer.pad_token]\n",
    "SEP = tokenizer.vocab[tokenizer.sep_token]\n",
    "\n",
    "enum_role = \"环节\"\n",
    "max_seq_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3948641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaiduEventDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_path, label_dict_path, ignore_index=-100):\n",
    "        self.label_vocab = load_dict(label_dict_path)\n",
    "        self.label_num = max(self.label_vocab.values()) + 1\n",
    "        self.examples = []\n",
    "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "            dataset = json.loads(f.read())\n",
    "            preprocess_dataset = data_process(dataset)\n",
    "            for d_json in preprocess_dataset:\n",
    "                tokens = d_json['tokens']\n",
    "                input_ids = tokenizer(tokens, is_split_into_words=True, add_special_tokens=True, max_length=max_seq_len, truncation=True)['input_ids']\n",
    "                tokens_input = input_ids + [PADDING] * (max_seq_len - len(input_ids))\n",
    "                attention_masks = self._get_attention_mask(input_ids, max_seq_len)\n",
    "                token_type_ids = self._get_token_type_id(input_ids, max_seq_len)\n",
    "                example = {\n",
    "                    \"input_ids\": tokens_input, \"attention_masks\": attention_masks, \"token_type_ids\": token_type_ids,\n",
    "                    \"seq_lens\": len(input_ids)\n",
    "                }\n",
    "                if 'labels' in d_json:\n",
    "                    labels = d_json['labels']\n",
    "                    labels = labels[:(max_seq_len - 2)]\n",
    "                    encoded_label = [\"O\"] + labels + [\"O\"]\n",
    "                    encoded_label = [self.label_vocab[x] for x in encoded_label] + [ignore_index] * (max_seq_len - 2 - len(labels))\n",
    "                    example.update({\"encoded_label\": encoded_label})\n",
    "                self.examples.append(example)\n",
    "\n",
    "    def _get_attention_mask(self, input_ids, max_seq_len):\n",
    "        \"\"\"Mask for padding.\"\"\"\n",
    "        if len(input_ids) > max_seq_len:\n",
    "            raise IndexError(\"Token length more than max seq length!\")\n",
    "        return [1] * len(input_ids) + [0] * (max_seq_len - len(input_ids))\n",
    "\n",
    "    def _get_token_type_id(self, input_ids, max_seq_len):\n",
    "        \"\"\"Segments: 0 for the first sequence, 1 for the second.\"\"\"\n",
    "        if len(input_ids) > max_seq_len:\n",
    "            raise IndexError(\"Token length more than max seq length!\")\n",
    "        segments = []\n",
    "        current_segment_id = 0\n",
    "        for input_id in input_ids:\n",
    "            segments.append(current_segment_id)\n",
    "            if input_id == SEP:\n",
    "                current_segment_id = 1\n",
    "        return segments + [0] * (max_seq_len - len(input_ids))        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, item_idx):\n",
    "        example = {\n",
    "            \"input_ids\": torch.tensor(self.examples[item_idx][\"input_ids\"]).long(),\n",
    "            \"attention_masks\": torch.tensor(self.examples[item_idx][\"attention_masks\"]),\n",
    "            \"token_type_ids\": torch.tensor(self.examples[item_idx][\"token_type_ids\"]),\n",
    "            \"seq_lens\": self.examples[item_idx][\"seq_lens\"]\n",
    "        }\n",
    "        if \"encoded_label\" in self.examples[item_idx]:\n",
    "            example.update({\"encoded_label\": torch.tensor(self.examples[item_idx][\"encoded_label\"], dtype=torch.long)})\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "597fd28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    \"\"\"Set the seed for generating random numbers on all GPUs.\n",
    "\n",
    "    It's safe to call this function if CUDA is not available; in that case, it is silently ignored.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): random numbers on all GPUs. Defaults to 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb7b93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BaiduEventDataset(dataset_path='./resources/duee_fin_train_preprocess.json', label_dict_path='./dictionary/trigger_tag.dict')\n",
    "dev_dataset = BaiduEventDataset(dataset_path='./resources/duee_fin_dev_preprocess.json', label_dict_path='./dictionary/trigger_tag.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68fc6480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 101, 2945, 5596, 6380, 5401, 5500,  124,  121, 3189, 3867, 2622, 8024,\n",
       "         2945, 4761, 2658,  782, 1894, 6851, 7463, 8024, 4415, 2682, 3749, 6756,\n",
       "         1440, 6401, 4052, 1762, 2832, 6598, 5442, 8024, 6369, 1153, 2828, 5401,\n",
       "         1744, 7674, 3613, 1062, 2458, 1247, 5500, 8020,  151,  158,  157, 8021,\n",
       "         1355, 6121,  817, 2137, 1762, 2875, 5500, 1277, 7313, 7553, 4999, 8024,\n",
       "         4493, 5635, 3291, 7770, 3717, 2398,  511, 8024, 6421, 1062, 1385, 3633,\n",
       "          809, 3680, 5500,  129,  118,  122,  121, 5401, 1039, 1355, 6121,  130,\n",
       "          126,  121,  121,  674, 5500, 5500, 4873,  511,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'attention_masks': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'seq_lens': 93,\n",
       " 'encoded_label': tensor([  26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,\n",
       "           26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,\n",
       "           26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,\n",
       "           26,   26,   26,   26,   26,   26,   26,   26,   20,   21,   21,   26,\n",
       "           26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,\n",
       "           26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,\n",
       "           26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,\n",
       "           26,   26,   26,   26,   26,   26,   26,   26,   26, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18b7265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "CUDA Device Count: 3\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    \n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', torch.cuda.memory_allocated(0)/1024**3, 'GB')\n",
    "    print('Cached:   ', torch.cuda.memory_reserved(0)/1024**3, 'GB')\n",
    "    \n",
    "    print('CUDA Device Count:', n_gpu)\n",
    "    \n",
    "set_seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae8682bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, eval_dataloader):\n",
    "    model.eval()\n",
    "    step = 0\n",
    "    eval_acc = 0.0\n",
    "    eval_f1 = 0.0\n",
    "    eval_precision = 0.0\n",
    "    eval_recall = 0.0\n",
    "    eval_loss = 0.0\n",
    "    for batch in eval_dataloader:\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'].to(device),\n",
    "            attention_mask=batch['attention_masks'].to(device),\n",
    "            token_type_ids=batch['token_type_ids'].to(device),\n",
    "            labels=batch['encoded_label'].to(device)\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        eval_loss += loss.item()\n",
    "        pred_list = torch.argmax(logits, dim=-1)\n",
    "        pred_Y, true_Y = [], []\n",
    "        for t_list, p_list, seq_len in zip(batch['encoded_label'].cpu().tolist(), pred_list.cpu().tolist(), batch['seq_lens']):\n",
    "            pred_Y.append([id2label.get(pid, \"O\") for pid in p_list[1: seq_len - 1]])\n",
    "            true_Y.append([id2label.get(tid, \"O\") for tid in t_list[1: seq_len - 1]])\n",
    "        eval_acc += accuracy_score(pred_Y, true_Y)\n",
    "        eval_precision += precision_score(pred_Y, true_Y, zero_division=1)\n",
    "        eval_recall += recall_score(pred_Y, true_Y, zero_division=1)\n",
    "        eval_f1 += f1_score(pred_Y, true_Y)\n",
    "        step += 1\n",
    "    model.train()\n",
    "    return eval_loss/step, eval_acc/step, eval_precision/step, eval_recall/step, eval_f1/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d34c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train model\n",
    "\n",
    "def train(model, ds_train, ds_dev = None, n_epochs = 100, learning_rate = 2e-5, weight_decay = 0.01, batch_size = 1, eval_per_epoch = 1):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_sampler = RandomSampler(ds_train)\n",
    "    train_dataloader = DataLoader(ds_train, sampler=train_sampler, batch_size=batch_size)\n",
    "    \n",
    "    eval_sampler = SequentialSampler(ds_dev)\n",
    "    eval_dataloader = DataLoader(ds_dev, sampler=eval_sampler, batch_size=batch_size)\n",
    "    \n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "\n",
    "#     if n_gpu > 1:\n",
    "#         model = torch.nn.DataParallel(model)\n",
    "\n",
    "    optimizer_grouped_parameters = [{\n",
    "        \"params\": model.parameters(),\n",
    "        \"lr\": learning_rate, \n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"apply_decay_param_fun\": lambda x: x in decay_params\n",
    "    }]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters)\n",
    "#     scheduler = ReduceLROnPlateau(optimizer, \"min\")\n",
    "    \n",
    "    f1 = 0.0\n",
    "    acc = 0.0\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    tr_loss = 0.0\n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    postfix = {}\n",
    "    for epoch in range(0, n_epochs):\n",
    "        eval_flag = False\n",
    "        train_iterator = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "        for batch in train_iterator:\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'].to(device),\n",
    "                # attention_mask=batch['attention_masks'].to(device),\n",
    "                token_type_ids=batch['token_type_ids'].to(device),\n",
    "                labels=batch['encoded_label'].to(device)\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "#             if n_gpu > 1:\n",
    "#                 loss = loss.mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step(loss)\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            pred_list = torch.argmax(logits, dim=-1)\n",
    "            pred_Y, true_Y = [], []\n",
    "            for t_list, p_list, seq_len in zip(batch['encoded_label'].cpu().tolist(), pred_list.cpu().tolist(), batch['seq_lens']):\n",
    "                pred_Y.append([id2label.get(pid, \"O\") for pid in p_list[1: seq_len - 1]])\n",
    "                true_Y.append([id2label.get(tid, \"O\") for tid in t_list[1: seq_len - 1]])\n",
    "            acc += accuracy_score(pred_Y, true_Y)\n",
    "            precision += precision_score(pred_Y, true_Y, zero_division=1)\n",
    "            recall += recall_score(pred_Y, true_Y, zero_division=1)\n",
    "            f1 += f1_score(pred_Y, true_Y)\n",
    "            model.zero_grad()\n",
    "\n",
    "            postfix.update({\"Avg loss\": f\"{tr_loss / (global_step + 1):.2f}\", \"Avg acc score\": f\"{acc / (global_step + 1):.2f}\", \"Avg precision score\": f\"{precision / (global_step + 1):.2f}\", \"Avg recall score\": f\"{recall / (global_step + 1):.2f}\", \"Avg f1 score\": f\"{f1 / (global_step + 1):.2f}\"})\n",
    "            if (\n",
    "                not eval_flag\n",
    "                and (global_step + 1) % len(train_dataloader) == 0\n",
    "                and (epoch % eval_per_epoch) == 0\n",
    "            ):\n",
    "                if ds_dev is not None:\n",
    "                    eval_loss, eval_acc, eval_precision, eval_recall, eval_f1 = evaluate(model, eval_dataloader)\n",
    "                postfix.update({\"Avg eval loss\": f\"{eval_loss:.2f}\", \"Avg eval acc\": f\"{eval_acc:.2f}\", \"Avg eval precision\": f\"{eval_precision:.2f}\", \"Avg eval recall\": f\"{eval_recall:.2f}\", \"Avg eval f1\": f\"{eval_f1:.2f}\"})\n",
    "                eval_flag = True\n",
    "            train_iterator.set_postfix(postfix)\n",
    "            global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8953ba8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ad4b4edbb8457a916074fad073a0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c70f1b904424d4fb8e9671c38a71ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848625272ecc42a9bf7c8586c4f75262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af81715c24043e0bdde36e6430c3e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c690e0f82454944afe723054a89a7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fe4df785774960a838a2f0c9ccb6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845c8d6796b94b468b5741d7825f469a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc0f4ee1ca94cb896d8e48b011d8a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffba5bcff5474826a71787dabadcec24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5b763e92a5440693b7c3f2062b3dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d81e45835549abb6c3449849ef751f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a00fdf0b4e4a0d9a0b1b6a8e9acca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dec59ecc6534302a66c002c5b0e885f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9bffa8d27849cab373c7152f6655ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984c96cb239f4684a4ab6a4e916a2336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf4d631455d4bb1882e49d6ad24a0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22663491e6c1442abe705f31ed3893ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e79a9cc8f14f9eb09ccde933b1fb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62df4a7a8b8a4324a2f84f143e4a0768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08930a676304a5597665142ac3fae33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataset, ds_dev=dev_dataset, n_epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8bcc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu(), './models/DuEE_fin/roberta-chinese-large/trigger.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7a31871",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cfab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
