{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b99e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, AutoModelForTokenClassification\n",
    "\n",
    "from crf_layer import CRFLayer\n",
    "from multiLabelTokenClassfication import MultiLabelTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474ba276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"hfl/chinese-roberta-wwm-ext-large\"\n",
    "\n",
    "\n",
    "enum_role = \"环节\"\n",
    "max_seq_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bedd926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset):\n",
    "    \"\"\"data_process\"\"\"\n",
    "\n",
    "    def label_data(data, start, l, _type):\n",
    "        \"\"\"label_data\"\"\"\n",
    "        for i in range(start, start + l):\n",
    "            suffix = \"B-\" if i == start else \"I-\"\n",
    "            if isinstance(data[i], str):\n",
    "                data[i] = []\n",
    "            solt = \"{}{}\".format(suffix, _type)\n",
    "            if solt not in data[i]:\n",
    "                data[i].append(solt)\n",
    "        return data\n",
    "\n",
    "    output = []\n",
    "    for d_json in dataset:\n",
    "        _id = d_json[\"id\"]\n",
    "        text_a = [\n",
    "            \"，\" if t == \" \" or t == \"\\n\" or t == \"\\t\" else t\n",
    "            for t in list(d_json[\"text\"].lower())\n",
    "        ]\n",
    "        labels = [\"O\"] * len(text_a)\n",
    "        if len(d_json.get(\"event_list\", [])) == 0:\n",
    "            continue\n",
    "        for event in d_json.get(\"event_list\", []):\n",
    "            event_type = event['event_type']\n",
    "            for arg in event[\"arguments\"]:\n",
    "                role_type = arg[\"role\"]\n",
    "                if role_type == enum_role:\n",
    "                    continue\n",
    "                argument = arg[\"argument\"]\n",
    "                start = arg[\"argument_start_index\"]\n",
    "                labels = label_data(labels, start, len(argument), role_type)\n",
    "        output.append({\n",
    "            \"tokens\": text_a, \"labels\": labels\n",
    "        })\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4af2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(dict_path):\n",
    "    \"\"\"load_dict\"\"\"\n",
    "    vocab = {}\n",
    "    for line in open(dict_path, 'r', encoding='utf-8'):\n",
    "        value, key = line.strip('\\n').split('\\t')\n",
    "        vocab[key] = int(value)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09abf029",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vocab = load_dict(dict_path='./dictionary/role_tag.dict')\n",
    "id2label = {val: key for key, val in label_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba347d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.num_labels = len(label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87567be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44aa16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = tokenizer.vocab[tokenizer.pad_token]\n",
    "SEP = tokenizer.vocab[tokenizer.sep_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870891b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaiduEventDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_path, label_dict_path, ignore_index=-100):\n",
    "        self.label_vocab = load_dict(label_dict_path)\n",
    "        self.label_num = max(self.label_vocab.values()) + 1\n",
    "        self.examples = []\n",
    "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "            dataset = json.loads(f.read())\n",
    "            preprocess_dataset = data_process(dataset)\n",
    "            for d_json in preprocess_dataset:\n",
    "                tokens = d_json['tokens']\n",
    "                input_ids = tokenizer(tokens, is_split_into_words=True, add_special_tokens=True, max_length=max_seq_len, truncation=True)['input_ids']\n",
    "                tokens_input = input_ids + [PADDING] * (max_seq_len - len(input_ids))\n",
    "                attention_masks = self._get_attention_mask(input_ids, max_seq_len)\n",
    "                token_type_ids = self._get_token_type_id(input_ids, max_seq_len)\n",
    "                example = {\n",
    "                    \"input_ids\": tokens_input, \"attention_masks\": attention_masks,\n",
    "                    \"token_type_ids\": token_type_ids, \"seq_lens\": len(input_ids)\n",
    "                }\n",
    "                if 'labels' in d_json:\n",
    "                    labels = d_json['labels']\n",
    "                    labels = labels[:(max_seq_len - 2)]\n",
    "                    encoded_label = [\"O\"] + labels + [\"O\"]\n",
    "                    encoded_label = self.to_one_hot_vector(encoded_label, max_seq_len - 2 - len(labels))\n",
    "                    example.update({\"encoded_label\": encoded_label})\n",
    "                self.examples.append(example)\n",
    "\n",
    "    def to_one_hot_vector(self, labels, zero_padding_len = 0):\n",
    "        \"\"\"Convert seq to one hot.\"\"\"\n",
    "        one_hot_vectors = []\n",
    "        for label in labels:\n",
    "            one_hot_vector = np.zeros(self.label_num)\n",
    "            if isinstance(label, str):\n",
    "                one_hot_vector[self.label_vocab.get(label, 0)] = 1\n",
    "            elif isinstance(label, list):\n",
    "                for l in label:\n",
    "                    one_hot_vector[self.label_vocab.get(l, 0)] = 1\n",
    "            one_hot_vectors.append(one_hot_vector)\n",
    "        for _ in range(zero_padding_len):\n",
    "            one_hot_vector = np.zeros(self.label_num)\n",
    "            one_hot_vectors.append(one_hot_vector)\n",
    "        return np.array(one_hot_vectors)\n",
    "\n",
    "    def _get_attention_mask(self, input_ids, max_seq_len):\n",
    "        \"\"\"Mask for padding.\"\"\"\n",
    "        if len(input_ids) > max_seq_len:\n",
    "            raise IndexError(\"Token length more than max seq length!\")\n",
    "        return [1] * len(input_ids) + [0] * (max_seq_len - len(input_ids))\n",
    "\n",
    "    def _get_token_type_id(self, input_ids, max_seq_len):\n",
    "        \"\"\"Segments: 0 for the first sequence, 1 for the second.\"\"\"\n",
    "        if len(input_ids) > max_seq_len:\n",
    "            raise IndexError(\"Token length more than max seq length!\")\n",
    "        segments = []\n",
    "        current_segment_id = 0\n",
    "        for input_id in input_ids:\n",
    "            segments.append(current_segment_id)\n",
    "            if input_id == SEP:\n",
    "                current_segment_id = 1\n",
    "        return segments + [0] * (max_seq_len - len(input_ids))        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, item_idx):\n",
    "        example = {\n",
    "            \"input_ids\": torch.tensor(self.examples[item_idx][\"input_ids\"]).long(),\n",
    "            \"attention_masks\": torch.tensor(self.examples[item_idx][\"attention_masks\"]),\n",
    "            \"token_type_ids\": torch.tensor(self.examples[item_idx][\"token_type_ids\"]),\n",
    "            \"seq_lens\": self.examples[item_idx][\"seq_lens\"]\n",
    "        }\n",
    "        if \"encoded_label\" in self.examples[item_idx]:\n",
    "            example.update({\"encoded_label\": torch.tensor(self.examples[item_idx][\"encoded_label\"], dtype=torch.float)})\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5903c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BaiduEventDataset(dataset_path='./resources/duee_fin_train_preprocess.json', label_dict_path='./dictionary/role_tag.dict')\n",
    "dev_dataset = BaiduEventDataset(dataset_path='./resources/duee_fin_dev_preprocess.json', label_dict_path='./dictionary/role_tag.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9cb3ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 101, 2945, 5596, 6380, 5401, 5500,  124,  121, 3189, 3867, 2622, 8024,\n",
       "         2945, 4761, 2658,  782, 1894, 6851, 7463, 8024, 4415, 2682, 3749, 6756,\n",
       "         1440, 6401, 4052, 1762, 2832, 6598, 5442, 8024, 6369, 1153, 2828, 5401,\n",
       "         1744, 7674, 3613, 1062, 2458, 1247, 5500, 8020,  151,  158,  157, 8021,\n",
       "         1355, 6121,  817, 2137, 1762, 2875, 5500, 1277, 7313, 7553, 4999, 8024,\n",
       "         4493, 5635, 3291, 7770, 3717, 2398,  511, 8024, 6421, 1062, 1385, 3633,\n",
       "          809, 3680, 5500,  129,  118,  122,  121, 5401, 1039, 1355, 6121,  130,\n",
       "          126,  121,  121,  674, 5500, 5500, 4873,  511,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'attention_masks': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'seq_lens': 93,\n",
       " 'encoded_label': tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32097756",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLabelTokenClassification(model_name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21aa23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    \"\"\"Set the seed for generating random numbers on all GPUs.\n",
    "\n",
    "    It's safe to call this function if CUDA is not available; in that case, it is silently ignored.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): random numbers on all GPUs. Defaults to 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8d34f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "CUDA Device Count: 3\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    \n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', torch.cuda.memory_allocated(0)/1024**3, 'GB')\n",
    "    print('Cached:   ', torch.cuda.memory_reserved(0)/1024**3, 'GB')\n",
    "    \n",
    "    print('CUDA Device Count:', n_gpu)\n",
    "    \n",
    "set_seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "569b24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, eval_dataloader):\n",
    "    model.eval()\n",
    "    step = 0\n",
    "    eval_acc = 0.0\n",
    "    eval_f1 = 0.0\n",
    "    eval_precision = 0.0\n",
    "    eval_recall = 0.0\n",
    "    eval_loss = 0.0\n",
    "    for batch in eval_dataloader:\n",
    "        loss, logits = model(\n",
    "            input_ids=batch['input_ids'].to(device),\n",
    "            attention_mask=batch['attention_masks'].to(device),\n",
    "            token_type_ids=batch['token_type_ids'].to(device),\n",
    "            labels=batch['encoded_label'].to(device)\n",
    "        )\n",
    "        \n",
    "        eval_loss += loss.item()\n",
    "        pred_Y = (torch.sigmoid(logits).data > 0.5).cpu().numpy()\n",
    "        true_Y = batch['encoded_label'].cpu().numpy()\n",
    "        pred, true = [], []\n",
    "        for t_ids, p_ids, seq_len in zip(true_Y, pred_Y, batch['seq_lens']):\n",
    "            pred.extend(p_ids[1: seq_len - 1])\n",
    "            true.extend(t_ids[1: seq_len - 1])\n",
    "        pred_Y = np.array(pred).flatten()\n",
    "        true_Y = np.array(true).flatten()\n",
    "        eval_acc += accuracy_score(pred_Y, true_Y)\n",
    "        eval_precision += precision_score(pred_Y, true_Y, average='macro', zero_division=1)\n",
    "        eval_recall += recall_score(pred_Y, true_Y, average='macro', zero_division=1)\n",
    "        eval_f1 += f1_score(pred_Y, true_Y, average='macro', zero_division=1)\n",
    "        step += 1\n",
    "    model.train()\n",
    "    return eval_loss/step, eval_acc/step, eval_precision/step, eval_recall/step, eval_f1/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b5dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train model\n",
    "\n",
    "def train(model, ds_train, ds_dev = None, n_epochs = 100, learning_rate = 5e-5, weight_decay = 0.01, batch_size = 1, eval_per_epoch = 1):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_sampler = RandomSampler(ds_train)\n",
    "    train_dataloader = DataLoader(ds_train, sampler=train_sampler, batch_size=batch_size)\n",
    "    \n",
    "    eval_sampler = SequentialSampler(ds_dev)\n",
    "    eval_dataloader = DataLoader(ds_dev, sampler=eval_sampler, batch_size=batch_size)\n",
    "    \n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "\n",
    "#     if n_gpu > 1:\n",
    "#         model = torch.nn.DataParallel(model)\n",
    "\n",
    "    optimizer_grouped_parameters = [{\n",
    "        \"params\": model.parameters(),\n",
    "        \"lr\": learning_rate, \n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"apply_decay_param_fun\": lambda x: x in decay_params\n",
    "    }]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters)\n",
    "#     scheduler = ReduceLROnPlateau(optimizer, \"min\")\n",
    "    \n",
    "    f1 = 0.0\n",
    "    acc = 0.0\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    tr_loss = 0.0\n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    postfix = {}\n",
    "    for epoch in range(0, n_epochs):\n",
    "        eval_flag = False\n",
    "        train_iterator = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "        for batch in train_iterator:\n",
    "            loss, logits = model(\n",
    "                input_ids=batch['input_ids'].to(device),\n",
    "                attention_mask=batch['attention_masks'].to(device),\n",
    "                token_type_ids=batch['token_type_ids'].to(device),\n",
    "                labels=batch['encoded_label'].to(device)\n",
    "            )\n",
    "            \n",
    "#             if n_gpu > 1:\n",
    "#                 loss = loss.mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step(loss)\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            pred_Y = (torch.sigmoid(logits).data > 0.5).cpu().numpy()\n",
    "            true_Y = batch['encoded_label'].cpu().numpy()\n",
    "            pred, true = [], []\n",
    "            for t_ids, p_ids, seq_len in zip(true_Y, pred_Y, batch['seq_lens']):\n",
    "                pred.extend(p_ids[1: seq_len - 1])\n",
    "                true.extend(t_ids[1: seq_len - 1])\n",
    "            pred_Y = np.array(pred).flatten()\n",
    "            true_Y = np.array(true).flatten()\n",
    "            acc += accuracy_score(pred_Y, true_Y)\n",
    "            precision += precision_score(pred_Y, true_Y, average='macro', zero_division=1)\n",
    "            recall += recall_score(pred_Y, true_Y, average='macro', zero_division=1)\n",
    "            f1 += f1_score(pred_Y, true_Y, average='macro', zero_division=1)\n",
    "            model.zero_grad()\n",
    "\n",
    "            postfix.update({\"Avg loss\": f\"{tr_loss / (global_step + 1):.2f}\", \"Avg acc score\": f\"{acc / (global_step + 1):.2f}\", \"Avg precision score\": f\"{precision / (global_step + 1):.2f}\", \"Avg recall score\": f\"{recall / (global_step + 1):.2f}\", \"Avg f1 score\": f\"{f1 / (global_step + 1):.2f}\"})\n",
    "            if (\n",
    "                not eval_flag\n",
    "                and (global_step + 1) % len(train_dataloader) == 0\n",
    "                and (epoch % eval_per_epoch) == 0\n",
    "            ):\n",
    "                if ds_dev is not None:\n",
    "                    eval_loss, eval_acc, eval_precision, eval_recall, eval_f1 = evaluate(model, eval_dataloader)\n",
    "                postfix.update({\"Avg eval loss\": f\"{eval_loss:.2f}\", \"Avg eval acc\": f\"{eval_acc:.2f}\", \"Avg eval precision\": f\"{eval_precision:.2f}\", \"Avg eval recall\": f\"{eval_recall:.2f}\", \"Avg eval f1\": f\"{eval_f1:.2f}\"})\n",
    "                eval_flag = True\n",
    "            train_iterator.set_postfix(postfix)\n",
    "            global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "213f4b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194d7ca88cef4564b202c8162a4dc261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d6ed1bb19a438386bc3d8ac9fa4d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6878b83e5a4c4498b22c5860755987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ec8fc5a8c24f97aac289d50b8c9303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ac629a07f149568e47b6a5a6905c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7bd824ea08495982cd2c4c60319e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c846d96fcd4af6a091155acc755c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb7d72f12a342eeb87df070b35efca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c2db6c46b34fe19f99af423542b8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9/20', max=454, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfc9d9c65a9402d90475a1d2c5d9594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372169d809954ff1bbd9c52ba855142f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f884e1d8671d46c4ade1e7c1e8c92681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7575695e8a43fda5e0ee3496da19cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e987d113f6ae49d58014b1246c5f12c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3ec0447e334438904e80c162a2fddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb74a50ad534aad89a646715605abcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1ebb4d1fd04caeb2cb4202e89a8f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c88c229210437f90714bb378bf295d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf206dc5fb841edad9695a0c5000504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014241095c184a4491632c573a107ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20/20', max=454, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataset, ds_dev=dev_dataset, n_epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62fe2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu(), './models/DuEE_fin/roberta-chinese-large/role-multilabel.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "458f733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25bbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "069d4b83295243b0bedfebb442b10c5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c4fd9ccefe95434db2e7df930aaac118",
       "style": "IPY_MODEL_e1c3e571d2b54106bf20fac3e33b5012",
       "value": " 130/274 [02:12&lt;02:26,  1.02s/it, Avg loss=1.23, Avg acc score=0.92, Avg f1 score=0.92]"
      }
     },
     "60f889e1229a4154aa318d4c46d16fe2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "80336ec9357f4abd8c4c3ba264963949": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8e3273f660b642669d155147b757f335",
        "IPY_MODEL_069d4b83295243b0bedfebb442b10c5b"
       ],
       "layout": "IPY_MODEL_f399e7b310cd4d1fb83bf06a20fc5d56"
      }
     },
     "8e3273f660b642669d155147b757f335": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "description": "Epoch 1/20:  47%",
       "layout": "IPY_MODEL_60f889e1229a4154aa318d4c46d16fe2",
       "max": 274,
       "style": "IPY_MODEL_c2f754305c5341929c539cca7dd9a9d2",
       "value": 130
      }
     },
     "c2f754305c5341929c539cca7dd9a9d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "c4fd9ccefe95434db2e7df930aaac118": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1c3e571d2b54106bf20fac3e33b5012": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f399e7b310cd4d1fb83bf06a20fc5d56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
